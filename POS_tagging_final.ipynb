{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXGXyvm2Npx0",
        "outputId": "43613c7b-b753-4a3c-8d3b-04f91071d8c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pennylane in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.39.0)\n",
            "Requirement already satisfied: numpy<2.1 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.26.4)\n",
            "Requirement already satisfied: scipy in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.13.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (3.4.2)\n",
            "Requirement already satisfied: rustworkx>=0.14.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.15.1)\n",
            "Requirement already satisfied: autograd in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.7.0)\n",
            "Requirement already satisfied: toml in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.10.2)\n",
            "Requirement already satisfied: appdirs in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (1.4.4)\n",
            "Requirement already satisfied: autoray>=0.6.11 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.7.0)\n",
            "Requirement already satisfied: cachetools in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (5.5.0)\n",
            "Requirement already satisfied: pennylane-lightning>=0.39 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (0.39.0)\n",
            "Requirement already satisfied: requests in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (4.11.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pennylane) (24.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->pennylane) (2024.2.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: qiskit in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.4)\n",
            "Requirement already satisfied: rustworkx>=0.15.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (0.15.1)\n",
            "Requirement already satisfied: numpy<3,>=1.17 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.5 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (1.13.0)\n",
            "Requirement already satisfied: sympy>=1.3 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (1.13.1)\n",
            "Requirement already satisfied: dill>=0.3 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (0.3.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (2.9.0.post0)\n",
            "Requirement already satisfied: stevedore>=3.0.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (5.3.0)\n",
            "Requirement already satisfied: typing-extensions in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (4.11.0)\n",
            "Requirement already satisfied: symengine<0.14,>=0.11 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from qiskit) (0.13.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from python-dateutil>=2.8.0->qiskit) (1.16.0)\n",
            "Requirement already satisfied: pbr>=2.0.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from stevedore>=3.0.0->qiskit) (6.1.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy>=1.3->qiskit) (1.3.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pennylane\n",
        "%pip install qiskit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.5.1)\n",
            "Requirement already satisfied: filelock in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (4.11.0)\n",
            "Requirement already satisfied: networkx in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (75.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hs tech\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5N6QodPOzxMB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "from qiskit import QuantumCircuit\n",
        "import pennylane as qml\n",
        "# import qiskit\n",
        "# from qlstm_pennylane import QLSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FeLptWA6zxMC"
      },
      "source": [
        "Here we define the possible tags: determinant, noun, verb."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "98L5FysgzxMC"
      },
      "outputs": [],
      "source": [
        "tag_to_ix = {\"DET\": 0, \"NN\": 1, \"V\": 2, \"PRON\":3,  \"ADV\":4, \"ADJ\":5, \"IN\":6}  # Assign each tag with a unique index\n",
        "ix_to_tag = {i:k for k,i in tag_to_ix.items()}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFuyoEXEzxMC"
      },
      "source": [
        "The function below tokenizes the sentence and matches the label to each word."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HAIkS4B9zxMD"
      },
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    idxs = [to_ix[w] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJicxsANzxMD"
      },
      "source": [
        "Now we can prepare the input dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqLpTrN7zxMD",
        "outputId": "f01b2420-6645-4b63-f081-5b18e5531042"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 421\n",
            "Number of tags: 9\n",
            "\n",
            "Dataset statistics:\n",
            "Total samples: 131\n",
            "Training samples: 104 (79.4%)\n",
            "Testing samples: 27 (20.6%)\n"
          ]
        }
      ],
      "source": [
        "vocab = [\n",
        "    # Tags are: DET - determiner; NN - noun; V - verb\n",
        "    # For example, the word \"The\" is a determiner\n",
        "    (\"The dog ate the apple\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"Everybody read that book\".split(), [\"NN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"She sings beautifully\".split(), [\"PRON\", \"V\", \"ADV\"]),\n",
        "    (\"The big red apple fell from the tree\".split(), [\"DET\", \"ADJ\", \"ADJ\", \"NN\", \"V\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"They ran quickly to the park\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"He read the book slowly\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\"]),\n",
        "    (\"The dogs barked loudly\".split(), [\"DET\", \"NN\", \"V\", \"ADV\"]),\n",
        "    (\"The tall building stood alone in the city\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She ate a delicious cake for dessert\".split(), [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"NN\"]),\n",
        "    (\"The children played happily in the park\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The boy climbed the tall tree\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"She carefully placed the vase on the table\".split(), [\"PRON\", \"ADV\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The wind howled loudly during the storm\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"A group of students studied together\".split(), [\"DET\", \"NN\", \"IN\", \"NN\", \"V\", \"ADV\"]),\n",
        "    (\"The teacher explained the lesson patiently\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\"]),\n",
        "    (\"He loves playing football with his friends\".split(), [\"PRON\", \"V\", \"V\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"They walked cautiously across the bridge\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The small kitten meowed loudly at night\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    (\"She opened the window to let in fresh air\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"V\", \"IN\", \"ADJ\", \"NN\"]),\n",
        "    (\"The man drove carefully in the rain\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The old woman told stories about her youth\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The scientist conducted an experiment in the lab\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"They argued heatedly over the results\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The children built a sandcastle on the beach\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"A colorful butterfly landed gently on the flower\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The sun rises early in the summer\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"He painted the house beautifully with vibrant colors\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"ADJ\", \"NN\"]),\n",
        "    (\"The artist created a masterpiece using oil paints\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"V\", \"NN\"]),\n",
        "    (\"The rain fell gently on the grass\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She walked briskly to the market\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The chef cooked an exquisite meal for the guests\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The boy threw the ball high into the air\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The river flows peacefully through the valley\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The crowd cheered loudly for the performers\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She tied her hair into a neat bun\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The horse galloped swiftly across the meadow\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The new student answered confidently in class\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    (\"He plays the piano beautifully during recitals\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    (\"The little boy ran excitedly to the playground\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She sketched a portrait of her mother\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The clock ticked loudly in the silent room\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"He sang softly to calm the crying baby\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"V\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The forest echoed with the sound of birds chirping\".split(), [\"DET\", \"NN\", \"V\", \"IN\", \"DET\", \"NN\", \"IN\", \"NN\", \"V\"]),\n",
        "    (\"They enjoyed the movie despite the loud noise\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The young girl spun gracefully on the ice\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The mountain was covered in a thick layer of snow\".split(), [\"DET\", \"NN\", \"V\", \"V\", \"IN\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"NN\"]),\n",
        "    (\"He eagerly waited for the exciting news\".split(), [\"PRON\", \"ADV\", \"V\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The flowers were arranged beautifully in the vase\".split(), [\"DET\", \"NN\", \"V\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The dancers moved rhythmically to the beat of the music\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She nervously answered the difficult question\".split(), [\"PRON\", \"ADV\", \"V\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The team celebrated their victory joyfully\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\"]),\n",
        "    (\"She discovered a hidden cave during the hike\".split(), [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The painter captured the sunset beautifully on canvas\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    (\"He adjusted the sails quickly to catch the wind\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"The baby crawled slowly across the room\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The farmer harvested the crops at dawn\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"NN\"]),\n",
        "    (\"She wore a scarf to protect herself from the cold\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"V\", \"PRON\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The orchestra played a symphony magnificently\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\"]),\n",
        "    (\"They explored the ancient ruins with great curiosity\".split(), [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"ADJ\", \"NN\"]),\n",
        "    (\"The artist painted vivid murals on the city walls\".split(), [\"DET\", \"NN\", \"V\", \"ADJ\", \"NN\", \"IN\", \"DET\", \"NN\", \"NN\"]),\n",
        "    (\"The birds flew high in the clear blue sky\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"ADJ\", \"ADJ\", \"NN\"]),\n",
        "    (\"He played chess intently with his grandfather\".split(), [\"PRON\", \"V\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The hikers rested briefly at the summit\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The musician composed a beautiful melody at night\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"NN\"]),\n",
        "    (\"She explained the instructions clearly to the group\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The children laughed loudly while playing in the yard\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"V\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"He admired the starry sky through his telescope\".split(), [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The chef prepared a feast for the entire family\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The mechanic fixed the engine carefully in the garage\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The scientist analyzed the data thoroughly before publishing\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"V\"]),\n",
        "    (\"The dog fetched the ball and brought it back\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"CONJ\", \"V\", \"PRON\", \"ADV\"]),\n",
        "    (\"She climbed the ladder cautiously to reach the top shelf\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"V\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The students practiced their presentation with enthusiasm\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"NN\"]),\n",
        "    (\"He observed the stars quietly through the telescope\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The little girl tied her shoes before running outside\".split(), [\"DET\", \"ADJ\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"V\", \"ADV\"]),\n",
        "    (\"The team worked hard to complete the challenging task\".split(), [\"DET\", \"NN\", \"V\", \"ADJ\", \"IN\", \"V\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"She polished the wooden table until it gleamed\".split(), [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"PRON\", \"V\"]),\n",
        "    (\"The students debated the topic passionately in class\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    (\"The cat chased the mouse into the dark corner\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"He poured a cup of tea and served it to his guest\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"IN\", \"NN\", \"CONJ\", \"V\", \"PRON\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The storm raged fiercely through the night\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"She meticulously arranged the flowers in the vase\".split(), [\"PRON\", \"ADV\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"The baby smiled brightly at her parents\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"They wandered aimlessly through the dense forest\".split(), [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    (\"The children eagerly opened their gifts on Christmas morning\".split(), [\"DET\", \"NN\", \"ADV\", \"V\", \"DET\", \"NN\", \"IN\", \"NN\", \"NN\"]),\n",
        "    (\"The librarian organized the books alphabetically on the shelves\".split(), [\"DET\", \"NN\", \"V\", \"DET\", \"NN\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"He gently placed the baby in the crib and kissed her forehead\".split(), [\"PRON\", \"ADV\", \"V\", \"DET\", \"NN\", \"IN\", \"DET\", \"NN\", \"CONJ\", \"V\", \"DET\", \"NN\"]),\n",
        "    (\"The athlete trained vigorously for the upcoming competition\".split(), [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    ([\"The\", \"cats\", \"slept\", \"on\", \"the\", \"mat.\"], [\"DET\", \"NN\", \"V\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"dances\", \"gracefully\", \"on\", \"stage.\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"NN\"]),\n",
        "    ([\"The\", \"flowers\", \"bloomed\", \"beautifully\", \"in\", \"the\", \"garden.\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"walked\", \"slowly\", \"down\", \"the\", \"street.\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"children\", \"played\", \"happily\", \"at\", \"the\", \"park.\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"ran\", \"quickly\", \"to\", \"catch\", \"the\", \"bus.\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"V\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"big\", \"yellow\", \"sun\", \"set\", \"over\", \"the\", \"ocean.\"], [\"DET\", \"ADJ\", \"ADJ\", \"NN\", \"V\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"wore\", \"a\", \"pretty\", \"dress\", \"to\", \"the\", \"party.\"], [\"PRON\", \"V\", \"DET\", \"ADJ\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"old\", \"men\", \"sat\", \"alone\", \"on\", \"the\", \"bench.\"], [\"DET\", \"ADJ\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"cat\", \"jumped\", \"over\", \"the\", \"fence\"], [\"DET\", \"NN\", \"V\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"A\", \"bird\", \"sang\", \"beautifully\", \"in\", \"the\", \"morning\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"ran\", \"quickly\", \"to\", \"catch\", \"the\", \"bus\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"V\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"students\", \"studied\", \"hard\", \"for\", \"the\", \"exam\"], [\"DET\", \"NN\", \"V\", \"ADJ\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"ate\", \"his\", \"dinner\", \"quietly\"], [\"PRON\", \"V\", \"DET\", \"NN\", \"ADV\"]),\n",
        "    ([\"The\", \"sun\", \"shone\", \"brightly\", \"on\", \"the\", \"beach\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"played\", \"happily\", \"in\", \"the\", \"park\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"flowers\", \"bloomed\", \"vividly\", \"in\", \"the\", \"garden\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"slept\", \"peacefully\", \"throughout\", \"the\", \"night\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"children\", \"laughed\", \"joyfully\", \"at\", \"the\", \"joke\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"spoke\", \"softly\", \"to\", \"his\", \"mother\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"baby\", \"cried\", \"loudly\", \"in\", \"the\", \"room\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"danced\", \"gracefully\", \"on\", \"the\", \"stage\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"horses\", \"galloped\", \"swiftly\", \"across\", \"the\", \"field\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"read\", \"carefully\", \"the\", \"instructions\"], [\"PRON\", \"V\", \"ADV\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"dog\", \"barked\", \"loudly\", \"at\", \"the\", \"stranger\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"swam\", \"gracefully\", \"in\", \"the\", \"ocean\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"paintings\", \"displayed\", \"beautifully\", \"in\", \"the\", \"gallery\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"wrote\", \"passionately\", \"about\", \"his\", \"experiences\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"sun\", \"set\", \"slowly\", \"behind\", \"the\", \"mountains\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"spoke\", \"confidently\", \"in\", \"front\", \"of\", \"the\", \"audience\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"NN\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"children\", \"played\", \"happily\", \"in\", \"the\", \"park\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"smiled\", \"warmly\", \"at\", \"his\", \"friends\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"car\", \"drove\", \"swiftly\", \"along\", \"the\", \"highway\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"answered\", \"quickly\", \"to\", \"his\", \"question\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"students\", \"listened\", \"attentively\", \"to\", \"the\", \"lecture\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"climbed\", \"bravely\", \"to\", \"the\", \"mountain\", \"peak\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\", \"NN\"]),\n",
        "    ([\"The\", \"rain\", \"fell\", \"heavily\", \"on\", \"the\", \"roof\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"She\", \"ran\", \"frantically\", \"to\", \"catch\", \"the\", \"bus\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"V\", \"DET\", \"NN\"]),\n",
        "    ([\"The\", \"flowers\", \"bloomed\", \"colorfully\", \"in\", \"the\", \"garden\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"He\", \"ate\", \"hungrily\", \"after\", \"a\", \"long\", \"day\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"ADJ\", \"NN\"]),\n",
        "    ([\"The\", \"cat\", \"purred\", \"contentedly\", \"on\", \"the\", \"windowsill\"], [\"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    ([\"They\", \"played\", \"enthusiastically\", \"in\", \"the\", \"playground\"], [\"PRON\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "    (\"We heard the birds chirping loudly in the morning\".split(), [\"PRON\", \"V\", \"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"]),\n",
        "]\n",
        "\n",
        "# Create word_to_ix dictionary\n",
        "word_to_ix = {}\n",
        "tag_to_ix = {}\n",
        "\n",
        "# First pass: collect all unique words and tags\n",
        "for sent, tags in vocab:\n",
        "    for word in sent:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "    for tag in tags:\n",
        "        if tag not in tag_to_ix:\n",
        "            tag_to_ix[tag] = len(tag_to_ix)\n",
        "\n",
        "# Add unknown tokens\n",
        "word_to_ix[\"<UNK>\"] = len(word_to_ix)\n",
        "tag_to_ix[\"<UNK>\"] = len(tag_to_ix)\n",
        "\n",
        "# Create reverse mapping for tags (useful for evaluation)\n",
        "ix_to_tag = {v: k for k, v in tag_to_ix.items()}\n",
        "\n",
        "# Print vocabulary statistics\n",
        "print(f\"Vocabulary size: {len(word_to_ix)}\")\n",
        "print(f\"Number of tags: {len(tag_to_ix)}\")\n",
        "\n",
        "def prepare_sequence(seq, to_ix):\n",
        "    # Add handling for unknown words/tags\n",
        "    idxs = [to_ix.get(w, to_ix[\"<UNK>\"]) for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Model parameters\n",
        "embedding_dim = 8\n",
        "hidden_dim = 6\n",
        "vocab_size = len(word_to_ix)\n",
        "tagset_size = len(tag_to_ix)\n",
        "n_epochs = 100\n",
        "\n",
        "# Calculate split indices\n",
        "total_samples = len(vocab)\n",
        "train_size = int(0.8 * total_samples)  # 80% for training\n",
        "test_size = total_samples - train_size  # 20% for testing\n",
        "\n",
        "# Shuffle and split the data\n",
        "import random\n",
        "random.seed(42)\n",
        "shuffled_vocab = vocab.copy()\n",
        "random.shuffle(shuffled_vocab)\n",
        "\n",
        "training_data = shuffled_vocab[:train_size]\n",
        "testing_data = shuffled_vocab[train_size:]\n",
        "\n",
        "# Print statistics\n",
        "print(f\"\\nDataset statistics:\")\n",
        "print(f\"Total samples: {total_samples}\")\n",
        "print(f\"Training samples: {len(training_data)} ({len(training_data)/total_samples*100:.1f}%)\")\n",
        "print(f\"Testing samples: {len(testing_data)} ({len(testing_data)/total_samples*100:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Shuffling the data before splitting to ensure random distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "random.seed(42)\n",
        "\n",
        "# Create shuffled copy of vocab\n",
        "shuffled_vocab = vocab.copy()\n",
        "random.shuffle(shuffled_vocab)\n",
        "\n",
        "# Split the shuffled data\n",
        "training_data = shuffled_vocab[:train_size]\n",
        "testing_data = shuffled_vocab[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "def prepare_sequence(seq, to_ix):\n",
        "    # Add handling for unknown words\n",
        "    idxs = [to_ix.get(w, to_ix[\"<UNK>\"]) if w in to_ix else to_ix[\"<UNK>\"] for w in seq]\n",
        "    return torch.tensor(idxs, dtype=torch.long)\n",
        "\n",
        "# Add unknown token to vocabulary\n",
        "word_to_ix[\"<UNK>\"] = len(word_to_ix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwySJCUnVhDH",
        "outputId": "c681a035-93fe-4605-ad32-6b02b508f77c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[(['The', 'scientist', 'conducted', 'an', 'experiment', 'in', 'the', 'lab'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The', 'students', 'studied', 'hard', 'for', 'the', 'exam'],\n",
              "  ['DET', 'NN', 'V', 'ADJ', 'IN', 'DET', 'NN']),\n",
              " (['The', 'old', 'men', 'sat', 'alone', 'on', 'the', 'bench.'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'nervously', 'answered', 'the', 'difficult', 'question'],\n",
              "  ['PRON', 'ADV', 'V', 'DET', 'ADJ', 'NN']),\n",
              " (['The', 'flowers', 'bloomed', 'beautifully', 'in', 'the', 'garden.'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'children', 'laughed', 'joyfully', 'at', 'the', 'joke'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['Everybody', 'read', 'that', 'book'], ['NN', 'V', 'DET', 'NN']),\n",
              " (['She', 'meticulously', 'arranged', 'the', 'flowers', 'in', 'the', 'vase'],\n",
              "  ['PRON', 'ADV', 'V', 'DET', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['She', 'sketched', 'a', 'portrait', 'of', 'her', 'mother'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The', 'farmer', 'harvested', 'the', 'crops', 'at', 'dawn'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'NN']),\n",
              " (['The', 'children', 'played', 'happily', 'in', 'the', 'park'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They', 'walked', 'cautiously', 'across', 'the', 'bridge'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'cat', 'chased', 'the', 'mouse', 'into', 'the', 'dark', 'corner'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['He', 'spoke', 'softly', 'to', 'his', 'mother'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'students', 'listened', 'attentively', 'to', 'the', 'lecture'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'tall', 'building', 'stood', 'alone', 'in', 'the', 'city'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He',\n",
              "   'painted',\n",
              "   'the',\n",
              "   'house',\n",
              "   'beautifully',\n",
              "   'with',\n",
              "   'vibrant',\n",
              "   'colors'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'ADV', 'IN', 'ADJ', 'NN']),\n",
              " (['The', 'flowers', 'bloomed', 'vividly', 'in', 'the', 'garden'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'flowers', 'were', 'arranged', 'beautifully', 'in', 'the', 'vase'],\n",
              "  ['DET', 'NN', 'V', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'storm', 'raged', 'fiercely', 'through', 'the', 'night'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'chef', 'cooked', 'an', 'exquisite', 'meal', 'for', 'the', 'guests'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'ADJ', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'painter',\n",
              "   'captured',\n",
              "   'the',\n",
              "   'sunset',\n",
              "   'beautifully',\n",
              "   'on',\n",
              "   'canvas'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV', 'IN', 'NN']),\n",
              " (['The', 'boy', 'threw', 'the', 'ball', 'high', 'into', 'the', 'air'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'answered', 'quickly', 'to', 'his', 'question'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['A', 'bird', 'sang', 'beautifully', 'in', 'the', 'morning'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They', 'ran', 'quickly', 'to', 'catch', 'the', 'bus.'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'V', 'DET', 'NN']),\n",
              " (['She', 'opened', 'the', 'window', 'to', 'let', 'in', 'fresh', 'air'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'IN', 'V', 'IN', 'ADJ', 'NN']),\n",
              " (['They', 'played', 'enthusiastically', 'in', 'the', 'playground'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'river', 'flows', 'peacefully', 'through', 'the', 'valley'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'sun', 'shone', 'brightly', 'on', 'the', 'beach'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'musician', 'composed', 'a', 'beautiful', 'melody', 'at', 'night'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'ADJ', 'NN', 'IN', 'NN']),\n",
              " (['He', 'admired', 'the', 'starry', 'sky', 'through', 'his', 'telescope'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['She', 'sings', 'beautifully'], ['PRON', 'V', 'ADV']),\n",
              " (['The', 'new', 'student', 'answered', 'confidently', 'in', 'class'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'NN']),\n",
              " (['The', 'baby', 'cried', 'loudly', 'in', 'the', 'room'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'wore', 'a', 'pretty', 'dress', 'to', 'the', 'party.'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The', 'teacher', 'explained', 'the', 'lesson', 'patiently'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV']),\n",
              " (['She', 'slept', 'peacefully', 'throughout', 'the', 'night'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'discovered', 'a', 'hidden', 'cave', 'during', 'the', 'hike'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['He', 'ate', 'hungrily', 'after', 'a', 'long', 'day'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['The', 'birds', 'flew', 'high', 'in', 'the', 'clear', 'blue', 'sky'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'ADJ', 'ADJ', 'NN']),\n",
              " (['The', 'team', 'celebrated', 'their', 'victory', 'joyfully'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV']),\n",
              " (['She', 'polished', 'the', 'wooden', 'table', 'until', 'it', 'gleamed'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'PRON', 'V']),\n",
              " (['She', 'tied', 'her', 'hair', 'into', 'a', 'neat', 'bun'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['She',\n",
              "   'wore',\n",
              "   'a',\n",
              "   'scarf',\n",
              "   'to',\n",
              "   'protect',\n",
              "   'herself',\n",
              "   'from',\n",
              "   'the',\n",
              "   'cold'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'IN', 'V', 'PRON', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'artist',\n",
              "   'painted',\n",
              "   'vivid',\n",
              "   'murals',\n",
              "   'on',\n",
              "   'the',\n",
              "   'city',\n",
              "   'walls'],\n",
              "  ['DET', 'NN', 'V', 'ADJ', 'NN', 'IN', 'DET', 'NN', 'NN']),\n",
              " (['The', 'little', 'boy', 'ran', 'excitedly', 'to', 'the', 'playground'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'wrote', 'passionately', 'about', 'his', 'experiences'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'sang', 'softly', 'to', 'calm', 'the', 'crying', 'baby'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'V', 'DET', 'ADJ', 'NN']),\n",
              " (['The', 'cats', 'slept', 'on', 'the', 'mat.'],\n",
              "  ['DET', 'NN', 'V', 'IN', 'DET', 'NN']),\n",
              " (['The', 'baby', 'smiled', 'brightly', 'at', 'her', 'parents'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'played', 'chess', 'intently', 'with', 'his', 'grandfather'],\n",
              "  ['PRON', 'V', 'NN', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'forest',\n",
              "   'echoed',\n",
              "   'with',\n",
              "   'the',\n",
              "   'sound',\n",
              "   'of',\n",
              "   'birds',\n",
              "   'chirping'],\n",
              "  ['DET', 'NN', 'V', 'IN', 'DET', 'NN', 'IN', 'NN', 'V']),\n",
              " (['The',\n",
              "   'athlete',\n",
              "   'trained',\n",
              "   'vigorously',\n",
              "   'for',\n",
              "   'the',\n",
              "   'upcoming',\n",
              "   'competition'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['They', 'argued', 'heatedly', 'over', 'the', 'results'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'ran', 'quickly', 'to', 'catch', 'the', 'bus'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'V', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'children',\n",
              "   'laughed',\n",
              "   'loudly',\n",
              "   'while',\n",
              "   'playing',\n",
              "   'in',\n",
              "   'the',\n",
              "   'yard'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'V', 'IN', 'DET', 'NN']),\n",
              " (['The', 'children', 'built', 'a', 'sandcastle', 'on', 'the', 'beach'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['He', 'ate', 'his', 'dinner', 'quietly'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'ADV']),\n",
              " (['The', 'clock', 'ticked', 'loudly', 'in', 'the', 'silent', 'room'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['The', 'horses', 'galloped', 'swiftly', 'across', 'the', 'field'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'ran', 'frantically', 'to', 'catch', 'the', 'bus'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'V', 'DET', 'NN']),\n",
              " (['He', 'observed', 'the', 'stars', 'quietly', 'through', 'the', 'telescope'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'children',\n",
              "   'eagerly',\n",
              "   'opened',\n",
              "   'their',\n",
              "   'gifts',\n",
              "   'on',\n",
              "   'Christmas',\n",
              "   'morning'],\n",
              "  ['DET', 'NN', 'ADV', 'V', 'DET', 'NN', 'IN', 'NN', 'NN']),\n",
              " (['The', 'chef', 'prepared', 'a', 'feast', 'for', 'the', 'entire', 'family'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['The',\n",
              "   'little',\n",
              "   'girl',\n",
              "   'tied',\n",
              "   'her',\n",
              "   'shoes',\n",
              "   'before',\n",
              "   'running',\n",
              "   'outside'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'DET', 'NN', 'IN', 'V', 'ADV']),\n",
              " (['The',\n",
              "   'students',\n",
              "   'practiced',\n",
              "   'their',\n",
              "   'presentation',\n",
              "   'with',\n",
              "   'enthusiasm'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'IN', 'NN']),\n",
              " (['She', 'read', 'carefully', 'the', 'instructions'],\n",
              "  ['PRON', 'V', 'ADV', 'DET', 'NN']),\n",
              " (['He',\n",
              "   'poured',\n",
              "   'a',\n",
              "   'cup',\n",
              "   'of',\n",
              "   'tea',\n",
              "   'and',\n",
              "   'served',\n",
              "   'it',\n",
              "   'to',\n",
              "   'his',\n",
              "   'guest'],\n",
              "  ['PRON',\n",
              "   'V',\n",
              "   'DET',\n",
              "   'NN',\n",
              "   'IN',\n",
              "   'NN',\n",
              "   'CONJ',\n",
              "   'V',\n",
              "   'PRON',\n",
              "   'IN',\n",
              "   'DET',\n",
              "   'NN']),\n",
              " (['She', 'ate', 'a', 'delicious', 'cake', 'for', 'dessert'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'NN']),\n",
              " (['A', 'colorful', 'butterfly', 'landed', 'gently', 'on', 'the', 'flower'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'eagerly', 'waited', 'for', 'the', 'exciting', 'news'],\n",
              "  ['PRON', 'ADV', 'V', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['He', 'plays', 'the', 'piano', 'beautifully', 'during', 'recitals'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'ADV', 'IN', 'NN']),\n",
              " (['The', 'cat', 'purred', 'contentedly', 'on', 'the', 'windowsill'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'boy', 'climbed', 'the', 'tall', 'tree'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'ADJ', 'NN']),\n",
              " (['The',\n",
              "   'librarian',\n",
              "   'organized',\n",
              "   'the',\n",
              "   'books',\n",
              "   'alphabetically',\n",
              "   'on',\n",
              "   'the',\n",
              "   'shelves'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'loves', 'playing', 'football', 'with', 'his', 'friends'],\n",
              "  ['PRON', 'V', 'V', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'mechanic',\n",
              "   'fixed',\n",
              "   'the',\n",
              "   'engine',\n",
              "   'carefully',\n",
              "   'in',\n",
              "   'the',\n",
              "   'garage'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They',\n",
              "   'explored',\n",
              "   'the',\n",
              "   'ancient',\n",
              "   'ruins',\n",
              "   'with',\n",
              "   'great',\n",
              "   'curiosity'],\n",
              "  ['PRON', 'V', 'DET', 'ADJ', 'NN', 'IN', 'ADJ', 'NN']),\n",
              " (['He', 'read', 'the', 'book', 'slowly'], ['PRON', 'V', 'DET', 'NN', 'ADV']),\n",
              " (['The', 'crowd', 'cheered', 'loudly', 'for', 'the', 'performers'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They', 'danced', 'gracefully', 'on', 'the', 'stage'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'young', 'girl', 'spun', 'gracefully', 'on', 'the', 'ice'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'mountain',\n",
              "   'was',\n",
              "   'covered',\n",
              "   'in',\n",
              "   'a',\n",
              "   'thick',\n",
              "   'layer',\n",
              "   'of',\n",
              "   'snow'],\n",
              "  ['DET', 'NN', 'V', 'V', 'IN', 'DET', 'ADJ', 'NN', 'IN', 'NN']),\n",
              " (['The', 'wind', 'howled', 'loudly', 'during', 'the', 'storm'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The',\n",
              "   'dancers',\n",
              "   'moved',\n",
              "   'rhythmically',\n",
              "   'to',\n",
              "   'the',\n",
              "   'beat',\n",
              "   'of',\n",
              "   'the',\n",
              "   'music'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['They', 'swam', 'gracefully', 'in', 'the', 'ocean'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They', 'climbed', 'bravely', 'to', 'the', 'mountain', 'peak'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN', 'NN']),\n",
              " (['The', 'children', 'played', 'happily', 'at', 'the', 'park.'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'dog', 'barked', 'loudly', 'at', 'the', 'stranger'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'man', 'drove', 'carefully', 'in', 'the', 'rain'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'cat', 'jumped', 'over', 'the', 'fence'],\n",
              "  ['DET', 'NN', 'V', 'IN', 'DET', 'NN']),\n",
              " (['They', 'enjoyed', 'the', 'movie', 'despite', 'the', 'loud', 'noise'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'IN', 'DET', 'ADJ', 'NN']),\n",
              " (['The', 'sun', 'set', 'slowly', 'behind', 'the', 'mountains'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['They', 'played', 'happily', 'in', 'the', 'park'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['The', 'old', 'woman', 'told', 'stories', 'about', 'her', 'youth'],\n",
              "  ['DET', 'ADJ', 'NN', 'V', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The', 'dog', 'ate', 'the', 'apple'], ['DET', 'NN', 'V', 'DET', 'NN']),\n",
              " (['The', 'horse', 'galloped', 'swiftly', 'across', 'the', 'meadow'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'spoke', 'confidently', 'in', 'front', 'of', 'the', 'audience'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'NN', 'IN', 'DET', 'NN']),\n",
              " (['The', 'orchestra', 'played', 'a', 'symphony', 'magnificently'],\n",
              "  ['DET', 'NN', 'V', 'DET', 'NN', 'ADV']),\n",
              " (['The', 'flowers', 'bloomed', 'colorfully', 'in', 'the', 'garden'],\n",
              "  ['DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['He', 'adjusted', 'the', 'sails', 'quickly', 'to', 'catch', 'the', 'wind'],\n",
              "  ['PRON', 'V', 'DET', 'NN', 'ADV', 'IN', 'V', 'DET', 'NN']),\n",
              " (['He', 'smiled', 'warmly', 'at', 'his', 'friends'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'DET', 'NN']),\n",
              " (['She', 'dances', 'gracefully', 'on', 'stage.'],\n",
              "  ['PRON', 'V', 'ADV', 'IN', 'NN'])]"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kvoDyjMMN9NR"
      },
      "outputs": [],
      "source": [
        "class QLSTM(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, n_qubits=4, n_qlayers=1, batch_first=True, return_sequences=False, return_state=False, backend=\"default.qubit\"):\n",
        "        super(QLSTM, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_qubits = n_qubits\n",
        "        self.n_qlayers = n_qlayers\n",
        "        self.batch_first = batch_first\n",
        "        self.return_sequences = return_sequences\n",
        "        self.return_state = return_state\n",
        "        self.concat_size = input_size + hidden_size\n",
        "        \n",
        "        # Initialize quantum devices\n",
        "        self.wires_per_block = [\"wire_\" + str(i) for i in range(n_qubits)]\n",
        "        self.dev = qml.device(backend, wires=self.wires_per_block)\n",
        "        \n",
        "        # Initialize quantum layers\n",
        "        weight_shapes = {\"weights\": (n_qlayers, n_qubits, 3)}\n",
        "        self.quantum_circuit = qml.qnn.TorchLayer(self.create_quantum_circuit(), weight_shapes)\n",
        "        \n",
        "        # Classical layers\n",
        "        self.linear_in = nn.Linear(self.concat_size, 2**n_qubits)  # Modified to output correct size\n",
        "        self.linear_hidden = nn.Linear(n_qubits, hidden_size)\n",
        "        \n",
        "        # Gate layers\n",
        "        self.forget_gate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.input_gate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.output_gate = nn.Linear(hidden_size, hidden_size)\n",
        "        self.cell_gate = nn.Linear(hidden_size, hidden_size)\n",
        "        \n",
        "        # Normalization and regularization\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def create_quantum_circuit(self):\n",
        "        @qml.qnode(self.dev, interface=\"torch\")\n",
        "        def circuit(inputs, weights):\n",
        "            # Ensure inputs is properly shaped and padded\n",
        "            inputs = inputs.reshape(-1)\n",
        "            padded_inputs = torch.zeros(2**self.n_qubits, dtype=inputs.dtype)\n",
        "            padded_inputs[:min(len(inputs), 2**self.n_qubits)] = inputs[:min(len(inputs), 2**self.n_qubits)]\n",
        "            padded_inputs = F.normalize(padded_inputs, p=2, dim=0)  # Normalize for quantum state\n",
        "            \n",
        "            # State preparation with padding\n",
        "            qml.QubitStateVector(padded_inputs, wires=self.wires_per_block, normalize=True)\n",
        "            \n",
        "            # Parameterized quantum circuit\n",
        "            for layer in range(self.n_qlayers):\n",
        "                # Rotation Layer\n",
        "                for i in range(self.n_qubits):\n",
        "                    qml.Rot(weights[layer, i, 0], \n",
        "                            weights[layer, i, 1], \n",
        "                            weights[layer, i, 2], \n",
        "                            wires=self.wires_per_block[i])\n",
        "                \n",
        "                # Entanglement Layer\n",
        "                for i in range(self.n_qubits - 1):\n",
        "                    qml.CNOT(wires=[self.wires_per_block[i], \n",
        "                                    self.wires_per_block[i + 1]])\n",
        "                \n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_per_block]\n",
        "        \n",
        "        return circuit\n",
        "\n",
        "    def create_custom_circuit_v1(self):\n",
        "        # Define the first custom circuit variant\n",
        "        @qml.qnode(self.dev, interface=\"torch\")\n",
        "        def circuit(inputs, weights):\n",
        "            # Implement the first custom circuit logic here\n",
        "            # ...\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_per_block]\n",
        "        \n",
        "        return circuit\n",
        "\n",
        "    def create_custom_circuit_v2(self):\n",
        "        # Define the second custom circuit variant\n",
        "        @qml.qnode(self.dev, interface=\"torch\")\n",
        "        def circuit(inputs, weights):\n",
        "            # Implement the second custom circuit logic here\n",
        "            # ...\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_per_block]\n",
        "        \n",
        "        return circuit\n",
        "\n",
        "    def create_custom_circuit_v3(self):\n",
        "        # Define the third custom circuit variant\n",
        "        @qml.qnode(self.dev, interface=\"torch\")\n",
        "        def circuit(inputs, weights):\n",
        "            # Implement the third custom circuit logic here\n",
        "            # ...\n",
        "            return [qml.expval(qml.PauliZ(wires=w)) for w in self.wires_per_block]\n",
        "        \n",
        "        return circuit\n",
        "\n",
        "    def forward(self, x, init_states=None):\n",
        "        batch_size = 1  # Since we're processing one sequence at a time\n",
        "        if init_states is None:\n",
        "            h_t = torch.zeros(batch_size, self.hidden_size)\n",
        "            c_t = torch.zeros(batch_size, self.hidden_size)\n",
        "        else:\n",
        "            h_t, c_t = init_states\n",
        "            \n",
        "        seq_length = x.size(0)\n",
        "        hidden_seq = []\n",
        "\n",
        "        for t in range(seq_length):\n",
        "            x_t = x[t:t+1]  # Keep batch dimension\n",
        "            \n",
        "            # Concatenate input and hidden state\n",
        "            v_t = torch.cat((x_t, h_t), dim=1)\n",
        "            \n",
        "            # Quantum processing\n",
        "            q_in = self.linear_in(v_t)\n",
        "            q_out = self.quantum_circuit(q_in)\n",
        "            q_out = self.linear_hidden(q_out)\n",
        "            q_out = self.layer_norm(q_out)\n",
        "            q_out = self.dropout(q_out)\n",
        "            \n",
        "            # LSTM gates\n",
        "            f_t = torch.sigmoid(self.forget_gate(q_out))\n",
        "            i_t = torch.sigmoid(self.input_gate(q_out))\n",
        "            o_t = torch.sigmoid(self.output_gate(q_out))\n",
        "            c_tilde = torch.tanh(self.cell_gate(q_out))\n",
        "            \n",
        "            # Update states\n",
        "            c_t = f_t * c_t + i_t * c_tilde\n",
        "            h_t = o_t * torch.tanh(c_t)\n",
        "            \n",
        "            hidden_seq.append(h_t)\n",
        "        \n",
        "        hidden_seq = torch.cat(hidden_seq, dim=0)\n",
        "        return hidden_seq"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "CIRCUIT 1 QLSTM VISUALIZATION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            \n",
            "q_0:  Ry(0.71523)  Rx(0.67636)  Ry(0.44421)  Rz(0.77514) \n",
            "      \n",
            "q_1:  Ry(0.61266)  Rx(0.048101)  Ry(0.88272)  X \n",
            "                \n",
            "q_2:  Ry(0.57242)  Rx(0.28842)  Ry(0.78137)  X \n",
            "                     \n",
            "q_3:  Ry(0.71523)  Rx(0.26651)  Ry(0.039348) \n",
            "                          \n",
            "c: 4/\n",
            "                                                                        \n",
            "                                                   \n",
            "q_0: M\n",
            "                                \n",
            "q_1:  Rz(0.70396) M\n",
            "               \n",
            "q_2:  Rz(0.098654) M\n",
            "                        \n",
            "q_3:  X  Rz(0.51557) M\n",
            "                            \n",
            "c: 4/\n",
            "                                        0     1  2  3 \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1207.22x451.5 with 1 Axes>"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n",
        "from qiskit.visualization import circuit_drawer\n",
        "import numpy as np\n",
        "\n",
        "def create_qiskit_circuit(n_qubits, inputs, weights):\n",
        "    \"\"\"\n",
        "    Create a Qiskit circuit equivalent to the PennyLane circuit\n",
        "    \n",
        "    Args:\n",
        "        n_qubits (int): Number of qubits\n",
        "        inputs (array-like): Input data for amplitude embedding\n",
        "        weights (array-like): Circuit weights (shape: [3, n_qubits])\n",
        "    \"\"\"\n",
        "    # Create quantum and classical registers\n",
        "    qr = QuantumRegister(n_qubits, 'q')\n",
        "    cr = ClassicalRegister(n_qubits, 'c')\n",
        "    circuit = QuantumCircuit(qr, cr)\n",
        "    \n",
        "    # Amplitude Embedding (simplified version)\n",
        "    # In practice, you'd need a more complex implementation for proper amplitude embedding\n",
        "    for i in range(n_qubits):\n",
        "        circuit.ry(inputs[i % len(inputs)], qr[i])\n",
        "    \n",
        "    # First variational layer\n",
        "    for i in range(n_qubits):\n",
        "        circuit.rx(weights[0][i], qr[i])  # RX gates\n",
        "    \n",
        "    for i in range(n_qubits):\n",
        "        circuit.ry(weights[1][i], qr[i])  # RY gates\n",
        "    \n",
        "    # CNOT chain\n",
        "    for i in range(n_qubits-1):\n",
        "        circuit.cx(qr[i], qr[i+1])\n",
        "    \n",
        "    # Second variational layer\n",
        "    for i in range(n_qubits):\n",
        "        circuit.rz(weights[2][i], qr[i])  # RZ gates\n",
        "    \n",
        "    # CZ chain\n",
        "    for i in range(n_qubits-1):\n",
        "        circuit.cz(qr[i], qr[i+1])\n",
        "    \n",
        "    # Measure all qubits\n",
        "    circuit.measure(qr, cr)\n",
        "    \n",
        "    return circuit\n",
        "\n",
        "# Create example inputs and weights\n",
        "n_qubits = 4\n",
        "inputs = np.random.random(3)  # 3 input values\n",
        "weights = np.random.random((3, n_qubits))  # 3 layers of weights\n",
        "\n",
        "# Create the circuit\n",
        "circuit = create_qiskit_circuit(n_qubits, inputs, weights)\n",
        "\n",
        "# Draw the circuit\n",
        "print(circuit.draw(output='text'))\n",
        "\n",
        "# For a more detailed visualization, you can also save it as an image\n",
        "circuit.draw(output='mpl', filename='qiskit_circuit.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hta5OmUmzxME"
      },
      "outputs": [],
      "source": [
        "class LSTMTagger(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size, n_qubits=0):\n",
        "        super(LSTMTagger, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        if n_qubits > 0:\n",
        "            print(\"Tagger will use Quantum LSTM\")\n",
        "            self.lstm = QLSTM(embedding_dim, hidden_dim, n_qubits=n_qubits)\n",
        "            self.is_quantum = True\n",
        "        else:\n",
        "            print(\"Tagger will use Classical LSTM\")\n",
        "            self.lstm = nn.LSTM(embedding_dim, hidden_dim, dropout=0.3, num_layers=2, bidirectional=True)\n",
        "            self.is_quantum = False\n",
        "            \n",
        "        lstm_output_dim = hidden_dim if self.is_quantum else hidden_dim * 2\n",
        "        self.hidden2tag = nn.Linear(lstm_output_dim, tagset_size)\n",
        "        self.layer_norm = nn.LayerNorm(lstm_output_dim)\n",
        "        \n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeddings(sentence)\n",
        "        embeds = self.dropout(embeds)\n",
        "        \n",
        "        if self.is_quantum:\n",
        "            lstm_out = self.lstm(embeds)\n",
        "        else:\n",
        "            lstm_out, _ = self.lstm(embeds.unsqueeze(1))\n",
        "            lstm_out = lstm_out.squeeze(1)\n",
        "            \n",
        "        lstm_out = self.layer_norm(lstm_out)\n",
        "        lstm_out = self.dropout(lstm_out)\n",
        "        tag_space = self.hidden2tag(lstm_out)\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "QuyZlHVKzxME"
      },
      "outputs": [],
      "source": [
        "# Model parameters\n",
        "embedding_dim = 8\n",
        "hidden_dim = 6\n",
        "n_qubits = 4\n",
        "n_epochs = 50  # Increased epochs\n",
        "batch_size = 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9LJiMsBzxMF",
        "outputId": "35d0ade8-67cc-42cd-df8d-a2b6ba9c4f48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tagger will use Classical LSTM\n"
          ]
        }
      ],
      "source": [
        "# Initialize model\n",
        "model_classical = LSTMTagger(\n",
        "    embedding_dim=embedding_dim,\n",
        "    hidden_dim=hidden_dim,\n",
        "    vocab_size=vocab_size,\n",
        "    tagset_size=tagset_size,\n",
        "    n_qubits=0\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuCrZc9fzxMF"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ZzcGZlk3zxMF"
      },
      "outputs": [],
      "source": [
        "# Training function modifications\n",
        "def train(model, n_epochs):\n",
        "    loss_function = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer, \n",
        "        T_0=10,  # First restart after 10 epochs\n",
        "        T_mult=2,  # Double the restart interval after each restart\n",
        "        eta_min=1e-6\n",
        "    )\n",
        "    \n",
        "    best_loss = float('inf')\n",
        "    patience = 15  # Increased patience\n",
        "    patience_counter = 0\n",
        "    \n",
        "    history = {\n",
        "        'loss': [],\n",
        "        'acc': [],\n",
        "        'val_loss': [],\n",
        "        'val_acc': []\n",
        "    }\n",
        "    \n",
        "    for epoch in range(n_epochs):\n",
        "        model.train()\n",
        "        losses = []\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        \n",
        "        # Training loop\n",
        "        for sentence, tags in training_data:\n",
        "            try:\n",
        "                model.zero_grad()\n",
        "                sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "                targets = prepare_sequence(tags, tag_to_ix)\n",
        "                \n",
        "                # Get model predictions\n",
        "                tag_scores = model(sentence_in)\n",
        "                \n",
        "                # Ensure tag_scores and targets have the same batch size\n",
        "                if tag_scores.size(0) != targets.size(0):\n",
        "                    # Trim the longer sequence to match the shorter one\n",
        "                    min_len = min(tag_scores.size(0), targets.size(0))\n",
        "                    tag_scores = tag_scores[:min_len]\n",
        "                    targets = targets[:min_len]\n",
        "                \n",
        "                loss = loss_function(tag_scores, targets)\n",
        "                \n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                \n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                \n",
        "                losses.append(float(loss))\n",
        "                all_preds.extend(tag_scores.argmax(dim=-1).tolist())\n",
        "                all_targets.extend(targets.tolist())\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"Error processing sentence: {sentence}\")\n",
        "                print(f\"Error message: {str(e)}\")\n",
        "                continue\n",
        "        \n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        val_losses = []\n",
        "        val_preds = []\n",
        "        val_targets = []\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            for sentence, tags in testing_data:\n",
        "                sentence_in = prepare_sequence(sentence, word_to_ix)\n",
        "                targets = prepare_sequence(tags, tag_to_ix)\n",
        "                \n",
        "                tag_scores = model(sentence_in)\n",
        "                \n",
        "                # Ensure tag_scores and targets have the same batch size\n",
        "                if tag_scores.size(0) != targets.size(0):\n",
        "                    min_len = min(tag_scores.size(0), targets.size(0))\n",
        "                    tag_scores = tag_scores[:min_len]\n",
        "                    targets = targets[:min_len]\n",
        "                \n",
        "                val_loss = loss_function(tag_scores, targets)\n",
        "                \n",
        "                val_losses.append(float(val_loss))\n",
        "                val_preds.extend(tag_scores.argmax(dim=-1).tolist())\n",
        "                val_targets.extend(targets.tolist())\n",
        "        \n",
        "        # Calculate metrics\n",
        "        avg_loss = np.mean(losses)\n",
        "        avg_val_loss = np.mean(val_losses)\n",
        "        \n",
        "        accuracy = np.mean([p == t for p, t in zip(all_preds, all_targets)])\n",
        "        val_accuracy = np.mean([p == t for p, t in zip(val_preds, val_targets)])\n",
        "        \n",
        "        scheduler.step(avg_val_loss)\n",
        "        \n",
        "        if avg_val_loss < best_loss:\n",
        "            best_loss = avg_val_loss\n",
        "            patience_counter = 0\n",
        "            torch.save(model.state_dict(), 'best_model.pt')\n",
        "        else:\n",
        "            patience_counter += 1\n",
        "            if patience_counter >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
        "                break\n",
        "        \n",
        "        history['loss'].append(avg_loss)\n",
        "        history['acc'].append(accuracy)\n",
        "        history['val_loss'].append(avg_val_loss)\n",
        "        history['val_acc'].append(val_accuracy)\n",
        "        \n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}\")\n",
        "        print(f\"Train Loss: {avg_loss:.4f} - Train Acc: {accuracy:.4f}\")\n",
        "        print(f\"Val Loss: {avg_val_loss:.4f} - Val Acc: {val_accuracy:.4f}\")\n",
        "        print(\"-\" * 50)\n",
        "    \n",
        "    model.load_state_dict(torch.load('best_model.pt'))\n",
        "    return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEFnWoV4zxMG",
        "outputId": "76072c5c-4ba2-4e27-8443-ba30bdba7857"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "Train Loss: 2.1962 - Train Acc: 0.1434\n",
            "Val Loss: 1.8725 - Val Acc: 0.2871\n",
            "--------------------------------------------------\n",
            "Epoch 2/25\n",
            "Train Loss: 1.9079 - Train Acc: 0.2395\n",
            "Val Loss: 1.7559 - Val Acc: 0.3861\n",
            "--------------------------------------------------\n",
            "Epoch 3/25\n",
            "Train Loss: 1.7759 - Train Acc: 0.3092\n",
            "Val Loss: 1.6685 - Val Acc: 0.4208\n",
            "--------------------------------------------------\n",
            "Epoch 4/25\n",
            "Train Loss: 1.7032 - Train Acc: 0.3592\n",
            "Val Loss: 1.5705 - Val Acc: 0.4604\n",
            "--------------------------------------------------\n",
            "Epoch 5/25\n",
            "Train Loss: 1.6228 - Train Acc: 0.3895\n",
            "Val Loss: 1.4654 - Val Acc: 0.4703\n",
            "--------------------------------------------------\n",
            "Epoch 6/25\n",
            "Train Loss: 1.5755 - Train Acc: 0.4092\n",
            "Val Loss: 1.3773 - Val Acc: 0.4703\n",
            "--------------------------------------------------\n",
            "Epoch 7/25\n",
            "Train Loss: 1.4843 - Train Acc: 0.4618\n",
            "Val Loss: 1.2783 - Val Acc: 0.5693\n",
            "--------------------------------------------------\n",
            "Epoch 8/25\n",
            "Train Loss: 1.4189 - Train Acc: 0.4895\n",
            "Val Loss: 1.2064 - Val Acc: 0.5990\n",
            "--------------------------------------------------\n",
            "Epoch 9/25\n",
            "Train Loss: 1.3583 - Train Acc: 0.5132\n",
            "Val Loss: 1.1225 - Val Acc: 0.6535\n",
            "--------------------------------------------------\n",
            "Epoch 10/25\n",
            "Train Loss: 1.3087 - Train Acc: 0.5382\n",
            "Val Loss: 1.0616 - Val Acc: 0.6733\n",
            "--------------------------------------------------\n",
            "Epoch 11/25\n",
            "Train Loss: 1.2535 - Train Acc: 0.5605\n",
            "Val Loss: 1.0180 - Val Acc: 0.6733\n",
            "--------------------------------------------------\n",
            "Epoch 12/25\n",
            "Train Loss: 1.1888 - Train Acc: 0.5974\n",
            "Val Loss: 0.9607 - Val Acc: 0.6980\n",
            "--------------------------------------------------\n",
            "Epoch 13/25\n",
            "Train Loss: 1.1364 - Train Acc: 0.5987\n",
            "Val Loss: 0.9227 - Val Acc: 0.6980\n",
            "--------------------------------------------------\n",
            "Epoch 14/25\n",
            "Train Loss: 1.1086 - Train Acc: 0.5974\n",
            "Val Loss: 0.8916 - Val Acc: 0.6931\n",
            "--------------------------------------------------\n",
            "Epoch 15/25\n",
            "Train Loss: 1.0965 - Train Acc: 0.6092\n",
            "Val Loss: 0.8701 - Val Acc: 0.6980\n",
            "--------------------------------------------------\n",
            "Epoch 16/25\n",
            "Train Loss: 1.0714 - Train Acc: 0.6224\n",
            "Val Loss: 0.8433 - Val Acc: 0.7030\n",
            "--------------------------------------------------\n",
            "Epoch 17/25\n",
            "Train Loss: 1.0373 - Train Acc: 0.6276\n",
            "Val Loss: 0.8151 - Val Acc: 0.7079\n",
            "--------------------------------------------------\n",
            "Epoch 18/25\n",
            "Train Loss: 0.9963 - Train Acc: 0.6658\n",
            "Val Loss: 0.7961 - Val Acc: 0.7030\n",
            "--------------------------------------------------\n",
            "Epoch 19/25\n",
            "Train Loss: 0.9569 - Train Acc: 0.6697\n",
            "Val Loss: 0.7740 - Val Acc: 0.7178\n",
            "--------------------------------------------------\n",
            "Epoch 20/25\n",
            "Train Loss: 0.9323 - Train Acc: 0.6697\n",
            "Val Loss: 0.7694 - Val Acc: 0.7376\n",
            "--------------------------------------------------\n",
            "Epoch 21/25\n",
            "Train Loss: 0.9068 - Train Acc: 0.6868\n",
            "Val Loss: 0.7515 - Val Acc: 0.7277\n",
            "--------------------------------------------------\n",
            "Epoch 22/25\n",
            "Train Loss: 0.8918 - Train Acc: 0.6803\n",
            "Val Loss: 0.7376 - Val Acc: 0.7376\n",
            "--------------------------------------------------\n",
            "Epoch 23/25\n",
            "Train Loss: 0.9088 - Train Acc: 0.6961\n",
            "Val Loss: 0.7303 - Val Acc: 0.7624\n",
            "--------------------------------------------------\n",
            "Epoch 24/25\n",
            "Train Loss: 0.8361 - Train Acc: 0.7211\n",
            "Val Loss: 0.7089 - Val Acc: 0.7772\n",
            "--------------------------------------------------\n",
            "Epoch 25/25\n",
            "Train Loss: 0.8390 - Train Acc: 0.7355\n",
            "Val Loss: 0.6922 - Val Acc: 0.7921\n",
            "--------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\HS Tech\\AppData\\Local\\Temp\\ipykernel_11656\\822005860.py:116: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('best_model.pt'))\n"
          ]
        }
      ],
      "source": [
        "history_classical = train(model_classical, n_epochs=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "hH1pV5k6zxMG"
      },
      "outputs": [],
      "source": [
        "def print_result(model):\n",
        "    with torch.no_grad():\n",
        "        input_sentence = \"We heard the birds chirping loudly in the morning\".split() #training_data[8][0]\n",
        "        labels = [\"PRON\", \"V\", \"DET\", \"NN\", \"V\", \"ADV\", \"IN\", \"DET\", \"NN\"] # training_data[8][1]\n",
        "        inputs = prepare_sequence(input_sentence, word_to_ix)\n",
        "        tag_scores = model(inputs)\n",
        "\n",
        "        tag_ids = torch.argmax(tag_scores, dim=1).numpy()\n",
        "        tag_labels = [ix_to_tag[k] for k in tag_ids]\n",
        "        print(f\"Sentence:  {input_sentence}\")\n",
        "        print(f\"Labels:    {labels}\")\n",
        "        print(f\"Predicted: {tag_labels}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9van-6JbzxMG",
        "outputId": "3dc5689f-4cdc-4cab-c1a4-42e73f8d1531"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sentence:  ['We', 'heard', 'the', 'birds', 'chirping', 'loudly', 'in', 'the', 'morning']\n",
            "Labels:    ['PRON', 'V', 'DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']\n",
            "Predicted: ['PRON', 'IN', 'DET', 'NN', 'V', 'ADV', 'IN', 'DET', 'NN']\n"
          ]
        }
      ],
      "source": [
        "print_result(model_classical)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiX9Ke21zxMG",
        "outputId": "4721c242-7461-49de-9410-8341b354a37f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tagger will use Quantum LSTM\n"
          ]
        }
      ],
      "source": [
        "n_qubits = 4\n",
        "\n",
        "model_quantum = LSTMTagger(embedding_dim,\n",
        "                        hidden_dim,\n",
        "                        vocab_size=len(word_to_ix),\n",
        "                        tagset_size=len(tag_to_ix),\n",
        "                        n_qubits=n_qubits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Circuit 1 Visualization\n",
        "def visualize_circuit_1():\n",
        "    n_qubits = 4\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    \n",
        "    # Data encoding\n",
        "    for i in range(n_qubits):\n",
        "        qc.h(i)\n",
        "        qc.ry(0.5, i)\n",
        "    \n",
        "    # Variational layer\n",
        "    for i in range(n_qubits):\n",
        "        qc.rx(0.1, i)\n",
        "        qc.ry(0.2, i)\n",
        "        qc.rz(0.3, i)\n",
        "    \n",
        "    # Entanglement\n",
        "    for i in range(n_qubits-1):\n",
        "        qc.cx(i, i+1)\n",
        "    \n",
        "    return qc.draw(output='mpl')\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "visualize_circuit_1()\n",
        "plt.title(\"Circuit 1 Architecture\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss = 0.2521, Accuracy = 57.05%\n",
            "Epoch 10: Loss = 0.0905, Accuracy = 74.19%\n",
            "Epoch 20: Loss = 0.0885, Accuracy = 74.63%\n",
            "Epoch 30: Loss = 0.0907, Accuracy = 74.61%\n",
            "Epoch 40: Loss = 0.0865, Accuracy = 74.52%\n"
          ]
        }
      ],
      "source": [
        "# First, let's set up the data correctly\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Example dataset with matching dimensions\n",
        "seq_length = 10  # Length of each sequence\n",
        "input_size = 3   # Number of features per time step\n",
        "hidden_size = 2  # Size of hidden state\n",
        "batch_size = 32  # Batch size\n",
        "\n",
        "# Create sample data\n",
        "X_train = torch.rand(100, seq_length, input_size)  # 100 samples, sequence length 10, 3 features each\n",
        "y_train = torch.rand(100, seq_length, hidden_size)  # Target should match model output dimensions\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Updated training function\n",
        "def train_circuit_1(epochs=50):\n",
        "    model = QLSTM(input_size=input_size, hidden_size=hidden_size, n_qubits=4)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Process each sequence in the batch\n",
        "            batch_output = []\n",
        "            for i in range(inputs.size(0)):  # For each item in the batch\n",
        "                output = model(inputs[i])  # Process sequence\n",
        "                batch_output.append(output)\n",
        "            \n",
        "            # Stack outputs\n",
        "            outputs = torch.stack(batch_output)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Computing accuracy (if needed)\n",
        "            # Note: This is a simplified accuracy metric for regression\n",
        "            with torch.no_grad():\n",
        "                accuracy = 1.0 - torch.mean(torch.abs(outputs - targets))\n",
        "                correct += accuracy.item() * targets.size(0)\n",
        "                total += targets.size(0)\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = (correct / total) * 100\n",
        "        \n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.2f}%')\n",
        "    \n",
        "    return losses, accuracies\n",
        "\n",
        "# Train the model\n",
        "losses_1, accuracies_1 = train_circuit_1()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 1 Performance Graph\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses_1)\n",
        "plt.title('Circuit 1 Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracies_1)\n",
        "plt.title('Circuit 1 Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 2 Visualization\n",
        "def visualize_circuit_2():\n",
        "    n_qubits = 4\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    \n",
        "    # Alternative architecture with different gate sequence\n",
        "    for i in range(n_qubits):\n",
        "        qc.h(i)\n",
        "    \n",
        "    # Double entanglement layer\n",
        "    for _ in range(2):\n",
        "        for i in range(n_qubits-1):\n",
        "            qc.cx(i, i+1)\n",
        "        for i in range(n_qubits):\n",
        "            qc.rz(0.1, i)\n",
        "    \n",
        "    return qc.draw(output='mpl')\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "visualize_circuit_2()\n",
        "plt.title(\"Circuit 2 Architecture\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 2 Training\n",
        "def train_circuit_2(epochs=25):\n",
        "    model = QLSTM(input_size=input_size, hidden_size=hidden_size, n_qubits=4)\n",
        "    model.quantum_circuit = qml.qnn.TorchLayer(model.create_custom_circuit_v2(), \n",
        "                                             {\"weights\": (model.n_qlayers, model.n_qubits, 3)})\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Process each sequence in the batch\n",
        "            batch_output = []\n",
        "            for i in range(inputs.size(0)):\n",
        "                output = model(inputs[i])\n",
        "                batch_output.append(output)\n",
        "            \n",
        "            # Stack outputs\n",
        "            outputs = torch.stack(batch_output)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Computing accuracy\n",
        "            with torch.no_grad():\n",
        "                accuracy = 1.0 - torch.mean(torch.abs(outputs - targets))\n",
        "                correct += accuracy.item() * targets.size(0)\n",
        "                total += targets.size(0)\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = (correct / total) * 100\n",
        "        \n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.2f}%')\n",
        "    \n",
        "    return losses, accuracies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 2 Performance Graph\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses_2)\n",
        "plt.title('Circuit 2 Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracies_2)\n",
        "plt.title('Circuit 2 Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 3 Visualization\n",
        "def visualize_circuit_3():\n",
        "    n_qubits = 4\n",
        "    qc = QuantumCircuit(n_qubits)\n",
        "    \n",
        "    # Alternative architecture with different gate sequence\n",
        "    for i in range(n_qubits):\n",
        "        qc.h(i)\n",
        "    \n",
        "    # Ring topology entanglement\n",
        "    for i in range(n_qubits):\n",
        "        qc.cx(i, (i+1)%n_qubits)\n",
        "    \n",
        "    # Final rotation layer\n",
        "    for i in range(n_qubits):\n",
        "        qc.ry(0.1, i)\n",
        "    \n",
        "    return qc.draw(output='mpl')\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "visualize_circuit_3()\n",
        "plt.title(\"Circuit 3 Architecture\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 3 Training\n",
        "def train_circuit_3(epochs=25):\n",
        "    model = QLSTM(input_size=input_size, hidden_size=hidden_size, n_qubits=4)\n",
        "    model.quantum_circuit = qml.qnn.TorchLayer(model.create_custom_circuit_v3(), \n",
        "                                             {\"weights\": (model.n_qlayers, model.n_qubits, 3)})\n",
        "    \n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "    criterion = nn.MSELoss()\n",
        "    \n",
        "    losses = []\n",
        "    accuracies = []\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # Process each sequence in the batch\n",
        "            batch_output = []\n",
        "            for i in range(inputs.size(0)):\n",
        "                output = model(inputs[i])\n",
        "                batch_output.append(output)\n",
        "            \n",
        "            # Stack outputs\n",
        "            outputs = torch.stack(batch_output)\n",
        "            \n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            \n",
        "            # Computing accuracy\n",
        "            with torch.no_grad():\n",
        "                accuracy = 1.0 - torch.mean(torch.abs(outputs - targets))\n",
        "                correct += accuracy.item() * targets.size(0)\n",
        "                total += targets.size(0)\n",
        "        \n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = (correct / total) * 100\n",
        "        \n",
        "        losses.append(epoch_loss)\n",
        "        accuracies.append(epoch_acc)\n",
        "        \n",
        "        if epoch % 10 == 0:\n",
        "            print(f'Epoch {epoch}: Loss = {epoch_loss:.4f}, Accuracy = {epoch_acc:.2f}%')\n",
        "    \n",
        "    return losses, accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Circuit 3 Performance Graph\n",
        "plt.figure(figsize=(12, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses_3)\n",
        "plt.title('Circuit 3 Training Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracies_3)\n",
        "plt.title('Circuit 3 Training Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comparison of all three circuits\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Loss Comparison\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(losses_1, label='Circuit 1')\n",
        "plt.plot(losses_2, label='Circuit 2')\n",
        "plt.plot(losses_3, label='Circuit 3')\n",
        "plt.title('Training Loss Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "# Accuracy Comparison\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(accuracies_1, label='Circuit 1')\n",
        "plt.plot(accuracies_2, label='Circuit 2')\n",
        "plt.plot(accuracies_3, label='Circuit 3')\n",
        "plt.title('Training Accuracy Comparison')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
